{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa5ad20-dd3a-43b9-8440-663f55c83e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this notebook trains and evaluates a simple teacher prognostic model on DFCI imaging reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dea9ca4-20b3-4f4a-912e-fe789b2a70eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes10/klkehl/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "532bc282-6728-402e-a89b-90a283ca97b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = pd.read_csv('/data/clin_notes_outcomes/profile_3-2023/derived_data/labeled_imaging_prissmm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fae8d3-11f9-4492-93e3-a472144257c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure progression is defined to include annotations of mixed response\n",
    "reports['progression'] = np.where(reports.class_status==3,1,reports.progression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbcfae4d-4f6c-452f-bcbe-4ebe527cdf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37274 entries, 0 to 37273\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Unnamed: 0.1              37274 non-null  int64  \n",
      " 1   dfci_mrn                  37274 non-null  float64\n",
      " 2   cancer_type               37274 non-null  object \n",
      " 3   image_scan_type           37274 non-null  float64\n",
      " 4   date                      37274 non-null  object \n",
      " 5   head_imaged               37274 non-null  float64\n",
      " 6   neck_imaged               37274 non-null  float64\n",
      " 7   spine_imaged              37274 non-null  float64\n",
      " 8   chest_imaged              37274 non-null  float64\n",
      " 9   abdomen_imaged            37274 non-null  float64\n",
      " 10  pelvis_imaged             37274 non-null  float64\n",
      " 11  any_cancer                37274 non-null  int64  \n",
      " 12  progression               37274 non-null  int64  \n",
      " 13  response                  37274 non-null  int64  \n",
      " 14  class_status              37261 non-null  float64\n",
      " 15  brain_met                 37274 non-null  float64\n",
      " 16  bone_met                  37274 non-null  float64\n",
      " 17  adrenal_met               37274 non-null  float64\n",
      " 18  liver_met                 37274 non-null  float64\n",
      " 19  lung_met                  37274 non-null  float64\n",
      " 20  node_met                  37274 non-null  int64  \n",
      " 21  peritoneal_met            37274 non-null  float64\n",
      " 22  extremity_imaged          37274 non-null  float64\n",
      " 23  whole_body_imaged         37274 non-null  float64\n",
      " 24  Unnamed: 0                37274 non-null  int64  \n",
      " 25  text                      37274 non-null  object \n",
      " 26  impression_text           27176 non-null  object \n",
      " 27  scan_type                 37274 non-null  object \n",
      " 28  patient_id                37274 non-null  int64  \n",
      " 29  hybrid_death_ind          37274 non-null  object \n",
      " 30  hybrid_death_dt           24152 non-null  object \n",
      " 31  primary_cancer_diagnosis  37274 non-null  object \n",
      " 32  genomics_date             37274 non-null  object \n",
      " 33  after_profile             37274 non-null  int64  \n",
      " 34  split                     37274 non-null  object \n",
      "dtypes: float64(17), int64(8), object(10)\n",
      "memory usage: 10.0+ MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5ef889-7db3-45ca-a318-4de62e40a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = reports[pd.to_datetime(reports.date) > pd.to_datetime(reports.genomics_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f69252ca-fd4d-4133-862a-1de9010e5567",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_scan_type\n",
       "1.0     14986\n",
       "3.0      4864\n",
       "7.0      1614\n",
       "5.0      1553\n",
       "11.0      187\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reports.image_scan_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa394745-0760-41e2-a81c-6b14f7cb3616",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_distribution = reports[reports.split=='train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c9f7b65-4f18-43cf-bef6-58c7595c48f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cancer_type\n",
       "nsclc_phase2_existing    0.287033\n",
       "crc                      0.170681\n",
       "breast                   0.154446\n",
       "prostate                 0.115238\n",
       "bladder                  0.097411\n",
       "pancreas                 0.093697\n",
       "rcc_barkouny             0.081494\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_distribution.cancer_type.value_counts()/check_distribution.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7358c91-bd83-4571-8751-8ad5378c790e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_status\n",
       "0.0    0.451454\n",
       "4.0    0.230794\n",
       "2.0    0.163094\n",
       "5.0    0.071360\n",
       "1.0    0.062765\n",
       "3.0    0.020320\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_distribution.class_status.value_counts()/check_distribution.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c58f4c-20c1-4a7e-9f26-d195d7dffe0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8029dc-a8aa-41de-a312-61bfd54258c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = reports[['dfci_mrn','date','hybrid_death_dt','hybrid_death_ind','text','split','any_cancer','progression','response','brain_met','bone_met','adrenal_met','liver_met','lung_met','node_met','peritoneal_met']]\n",
    "to_train['text'] = to_train.text.str.lower()\n",
    "to_train['date'] = pd.to_datetime(to_train.date)\n",
    "to_train['hybrid_death_dt'] = pd.to_datetime(to_train.hybrid_death_dt)\n",
    "to_train['death_date'] = np.where(to_train.hybrid_death_dt > pd.to_datetime('2022-12-31'), pd.to_datetime('2022-12-31'), to_train.hybrid_death_dt)\n",
    "\n",
    "#to_train['died'] = 0.\n",
    "to_train['died'] = np.where(np.logical_and(to_train.hybrid_death_ind == \"Y\", to_train.hybrid_death_dt <= pd.to_datetime('2022-12-31')),  1., 0.)\n",
    "to_train['death_date'] = np.where(to_train.death_date.isnull(), pd.to_datetime('2022-12-31'), to_train.death_date)\n",
    "\n",
    "to_train.head()\n",
    "to_train['time_to_death'] = ((pd.to_datetime(to_train['death_date']) - pd.to_datetime(to_train['date'])).dt.days)/30\n",
    "to_train[['date','death_date','time_to_death']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8d03a80-0a9e-4c0c-882e-ad87ba238dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = to_train[to_train.split=='train']\n",
    "#training['length'] = training.text.str.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "694749eb-9d1c-4413-bad7-7c272eccb2d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18848"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d002c1c-608e-48d9-917b-004cf4485e44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.dfci_mrn.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd189b4-76c4-4051-8443-6536ac42474d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d24852-0db6-4eea-a675-92b3661aad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = to_train[to_train.split=='validation']\n",
    "#validation['length'] = validation.text.str.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b2e0bd9-3f8a-44d7-ad9f-8be0476cdeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = to_train[to_train.split=='test']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13887e9d-2b92-4e30-b52e-bd4b24b34d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class LabeledDataset(data.Dataset):\n",
    "    def __init__(self, pandas_dataset):\n",
    "        self.data = pandas_dataset.copy()\n",
    "        self.indices = self.data.index.unique()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', truncation_side='left')        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # how many notes in the dataset\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data for notes corresponding to indices passed\n",
    "        this_index = self.indices[index]\n",
    "        pand = self.data.loc[this_index, :]\n",
    "    \n",
    "        encoded = self.tokenizer(pand['text'], padding='max_length', truncation=True)\n",
    "\n",
    "        x_text_tensor = torch.tensor(encoded.input_ids, dtype=torch.long)\n",
    "        x_attention_mask = torch.tensor(encoded.attention_mask, dtype=torch.long)\n",
    "\n",
    "        y_time_to_death = torch.tensor(pand.time_to_death, dtype=torch.float32)\n",
    "        y_died = torch.tensor(pand.died, dtype=torch.float32)\n",
    "        \n",
    "     \n",
    "        return x_text_tensor, x_attention_mask, y_time_to_death, y_died\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cb1bacc-51e5-4821-83da-550dd6eebcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import LSTM, Linear, Embedding, Conv1d, MaxPool1d, GRU, LSTMCell, Dropout, Module, Sequential, ReLU\n",
    "\n",
    "   \n",
    "class PrognosisModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PrognosisModel, self).__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.risk_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x_text_tensor, x_attention_mask):\n",
    "        # x should be tuple of input IDs, then attention mask\n",
    "        \n",
    "        main = self.bert(x_text_tensor, x_attention_mask)\n",
    "        main = main.last_hidden_state[:,0,:].squeeze(1)\n",
    "\n",
    "                                          \n",
    "        risk_out = F.sigmoid(self.risk_head(main))\n",
    "\n",
    "        return  risk_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e20715-6f56-45a3-822b-0d479d4e90ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation = nn.Softplus()\n",
    "def survival_loss(linear_h, end_times, events):\n",
    "    #hazard = activation(linear_h)\n",
    "    hazard = linear_h\n",
    "    \n",
    "    cum_hazard = hazard * end_times\n",
    "\n",
    "    loss = -torch.sum(torch.log(hazard)*events - cum_hazard)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e32ab8ca-02ae-458c-89a7-b6344c7476c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW, Adam\n",
    "#, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def train_model(model, num_epochs, trainloader, validloader=None, device='cuda'):\n",
    "    \n",
    "    \n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    num_training_steps = num_epochs * len(trainloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):  \n",
    "        running_train_loss = 0.0\n",
    "        mean_train_loss = 0.0\n",
    "        \n",
    "        running_valid_loss = 0.0\n",
    "        mean_valid_loss = 0.0\n",
    "\n",
    "        num_train_batches = len(trainloader)\n",
    "                \n",
    "        model.train()\n",
    "\n",
    "        preds_h_list = []\n",
    "        times_list = []\n",
    "        events_list = []\n",
    "\n",
    "        num_dead = 0\n",
    "\n",
    "        model.train()\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "            input_ids, input_masks, time_to_death, died = [x.to(device) for x in batch]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_h_t = model(input_ids, input_masks)\n",
    "            pred_h_t = pred_h_t.squeeze(1)\n",
    "            \n",
    "            preds_h_list.append(pred_h_t)\n",
    "            times_list.append(time_to_death)\n",
    "            events_list.append(died)\n",
    "\n",
    "            num_dead += died.sum()\n",
    "\n",
    "            if num_dead >= 3:\n",
    "                pred_h_t = torch.cat(preds_h_list)\n",
    "                times = torch.cat(times_list)\n",
    "                events = torch.cat(events_list)\n",
    "                \n",
    "                prognosis_loss = survival_loss(pred_h_t, times, events)\n",
    "                prognosis_loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "                running_train_loss += prognosis_loss.data.cpu().numpy()\n",
    "                mean_train_loss = running_train_loss / (i+1)\n",
    "                \n",
    "           \n",
    "                preds_h_list = []\n",
    "                times_list = []\n",
    "                events_list = []\n",
    "        \n",
    "                num_dead = 0\n",
    "\n",
    "            print('Training Epoch: ' + str(epoch+1) + ', batch: ' + str(i + 1) + '/' + str(num_train_batches) + ' this_loss:' + str(prognosis_loss.detach().cpu().numpy()) \n",
    "                  +', train loss: ' + str(mean_train_loss), end='\\r', flush=True)\n",
    "        \n",
    "        print('\\n')\n",
    "        # eval on valid\n",
    "        \n",
    "        if validloader is not None:\n",
    "            model.eval()\n",
    "            preds_h_list = []\n",
    "            times_list = []\n",
    "            events_list = []\n",
    "    \n",
    "            num_dead = 0\n",
    "            \n",
    "            for i, batch in enumerate(validloader, 0):\n",
    "                input_ids, input_masks, time_to_death, died = [x.to(device) for x in batch]\n",
    "                    \n",
    "                with torch.no_grad():\n",
    "                    pred_h_t = model(input_ids, input_masks)\n",
    "                    pred_h_t = pred_h_t.squeeze(1)\n",
    "                \n",
    "                preds_h_list.append(pred_h_t)\n",
    "                times_list.append(time_to_death)\n",
    "                events_list.append(died)\n",
    "    \n",
    "                num_dead += died.sum()\n",
    "    \n",
    "                if num_dead >= 3:\n",
    "                    pred_h_t = torch.cat(preds_h_list)\n",
    "                    times = torch.cat(times_list)\n",
    "                    events = torch.cat(events_list)\n",
    "                    \n",
    "                    prognosis_loss = survival_loss(pred_h_t, times, events)\n",
    "    \n",
    "                    running_valid_loss += prognosis_loss.data.cpu().numpy()\n",
    "                    \n",
    "               \n",
    "                    preds_h_list = []\n",
    "                    times_list = []\n",
    "                    events_list = []\n",
    "            \n",
    "                    num_dead = 0\n",
    "\n",
    "            mean_valid_loss = running_valid_loss / (i+1)\n",
    "\n",
    "    \n",
    "            print('Validation Epoch: ' + str(epoch+1) +', validation loss: ' + str(mean_valid_loss), end='\\r', flush=True)\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f34176e-156b-4929-bf71-0fc4bf26f85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # actual training code, commented out after model was trained\n",
    "\n",
    "# training_small = training.sample(100)\n",
    "# validation_small = validation.sample(100)\n",
    "\n",
    "# themodel = PrognosisModel().to('cuda')\n",
    "# trainloader = data.DataLoader(LabeledDataset(training.reset_index(drop=True)), batch_size=16, num_workers=8, shuffle=True)\n",
    "# validloader = data.DataLoader(LabeledDataset(validation.reset_index(drop=True)), batch_size=16, num_workers=8, shuffle=True)\n",
    "# train_model(themodel,3, trainloader, validloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b08de9d2-012a-4541-8107-9e9451200bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(themodel.state_dict(), './imaging_prognosis_model_teacher.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "636e5eed-e383-4a15-9379-acc76507f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out actual test dataset\n",
    "themodel = PrognosisModel()\n",
    "themodel.load_state_dict(torch.load('./imaging_prognosis_model_teacher.pt'))\n",
    "themodel.to('cuda')\n",
    "\n",
    "themodel.eval()\n",
    "\n",
    "no_shuffle_valid_dataset = data.DataLoader(LabeledDataset(test), batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "event_times = []\n",
    "events = []\n",
    "output_prediction_list = []\n",
    "for batch in no_shuffle_valid_dataset:\n",
    "    x_text_ids = batch[0].to('cuda')\n",
    "    x_attention_mask = batch[1].to('cuda')\n",
    "    event_times.append(batch[2].detach().cpu().numpy())\n",
    "    events.append(batch[3].detach().cpu().numpy())\n",
    "    with torch.no_grad():\n",
    "        predictions = themodel(x_text_ids, x_attention_mask).detach().cpu().numpy()\n",
    "    output_prediction_list.append(predictions)\n",
    "\n",
    "\n",
    "output_predictions = np.concatenate(output_prediction_list).squeeze(1)\n",
    "event_times = np.concatenate(event_times)\n",
    "events = np.concatenate(events)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0acf483f-0e5e-4787-8cf3-40a51de6e866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba5cd5d6-0e4a-4e93-8346-c9f94c2aa5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7586501054237722, 1451832, 461872, 1, 181)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concordance_index_censored(np.where(events==1, True, False), event_times, output_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c8976-d234-4306-8dec-05ef3c2c6715",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
