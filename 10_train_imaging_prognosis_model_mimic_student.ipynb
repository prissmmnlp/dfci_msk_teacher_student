{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook trains a student prognostic model on MIMIC imaging reports and evaluates it on DFCI test imaging reports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/homes10/klkehl/miniconda3/envs/llm/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic = pd.read_csv('/data/clin_notes_outcomes/mimic-iv-note-deidentified-free-text-clinical-notes-2.2/mimic-iv-note-deidentified-free-text-clinical-notes-2.2/note/radiology.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2321355 entries, 0 to 2321354\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   note_id     object \n",
      " 1   subject_id  int64  \n",
      " 2   hadm_id     float64\n",
      " 3   note_type   object \n",
      " 4   note_seq    int64  \n",
      " 5   charttime   object \n",
      " 6   storetime   object \n",
      " 7   text        object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 141.7+ MB\n"
     ]
    }
   ],
   "source": [
    "mimic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cancer = mimic[mimic.text.str.lower().str.contains('cancer|restaging|malignan')] \n",
    "mimic_cancer = mimic_cancer[mimic_cancer.text.str.lower().str.contains('ct |mr |pet |nm |mammo')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 217642 entries, 9 to 2321304\n",
      "Data columns (total 8 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   note_id     217642 non-null  object \n",
      " 1   subject_id  217642 non-null  int64  \n",
      " 2   hadm_id     55804 non-null   float64\n",
      " 3   note_type   217642 non-null  object \n",
      " 4   note_seq    217642 non-null  int64  \n",
      " 5   charttime   217642 non-null  object \n",
      " 6   storetime   217642 non-null  object \n",
      " 7   text        217642 non-null  object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 14.9+ MB\n"
     ]
    }
   ],
   "source": [
    "mimic_cancer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mimic_cancer['text'] = mimic_cancer['text'].str.lower().str.replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi_data = pd.read_csv('/data/clin_notes_outcomes/profile_3-2023/derived_data/labeled_imaging_prissmm.csv')\n",
    "\n",
    "# define mixed response to be progression\n",
    "phi_data['text'] = phi_data.text.str.lower().str.replace(\"\\n\", \" \")\n",
    "phi_data['progression'] = np.where(phi_data.class_status==3, 1, phi_data.progression)\n",
    "phi_data = phi_data[pd.to_datetime(phi_data.date) > pd.to_datetime(phi_data.genomics_date)]\n",
    "\n",
    "phi_data = phi_data[['dfci_mrn','date','hybrid_death_dt','hybrid_death_ind','text','split','any_cancer','progression','response','brain_met','bone_met','adrenal_met','liver_met','lung_met','node_met','peritoneal_met']]\n",
    "phi_data['text'] = phi_data.text.str.lower()\n",
    "phi_data['date'] = pd.to_datetime(phi_data.date)\n",
    "phi_data['hybrid_death_dt'] = pd.to_datetime(phi_data.hybrid_death_dt)\n",
    "phi_data['death_date'] = np.where(phi_data.hybrid_death_dt > pd.to_datetime('2022-12-31'), pd.to_datetime('2022-12-31'), phi_data.hybrid_death_dt)\n",
    "\n",
    "#phi_data['died'] = 0.\n",
    "phi_data['died'] = np.where(np.logical_and(phi_data.hybrid_death_ind == \"Y\", phi_data.hybrid_death_dt <= pd.to_datetime('2022-12-31')),  1., 0.)\n",
    "phi_data['death_date'] = np.where(phi_data.death_date.isnull(), pd.to_datetime('2022-12-31'), phi_data.death_date)\n",
    "\n",
    "phi_data.head()\n",
    "phi_data['time_to_death'] = ((pd.to_datetime(phi_data['death_date']) - pd.to_datetime(phi_data['date'])).dt.days)/30\n",
    "phi_data[['date','death_date','time_to_death']]\n",
    "#phi_data.class_status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = phi_data[phi_data.split=='validation']\n",
    "\n",
    "#validation.head()\n",
    "#validation['length'] = validation.text.str.count(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = phi_data[phi_data.split=='test']\n",
    "\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class UnLabeledDataset(data.Dataset):\n",
    "    def __init__(self, pandas_dataset):\n",
    "        self.data = pandas_dataset.copy()\n",
    "        self.indices = self.data.index.unique()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', truncation_side='left')        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # how many notes in the dataset\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data for notes corresponding to indices passed\n",
    "        this_index = self.indices[index]\n",
    "        pand = self.data.loc[this_index, :]\n",
    "    \n",
    "        encoded = self.tokenizer(pand['text'], padding='max_length', truncation=True)\n",
    "\n",
    "        x_text_tensor = torch.tensor(encoded.input_ids, dtype=torch.long)\n",
    "        x_attention_mask = torch.tensor(encoded.attention_mask, dtype=torch.long)\n",
    "\n",
    "\n",
    "        return x_text_tensor, x_attention_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import LSTM, Linear, Embedding, Conv1d, MaxPool1d, GRU, LSTMCell, Dropout, Module, Sequential, ReLU\n",
    "\n",
    "   \n",
    "class PrognosisModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PrognosisModel, self).__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.risk_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x_text_tensor, x_attention_mask):\n",
    "        # x should be tuple of input IDs, then attention mask\n",
    "        \n",
    "        main = self.bert(x_text_tensor, x_attention_mask)\n",
    "        main = main.last_hidden_state[:,0,:].squeeze(1)\n",
    "\n",
    "                                          \n",
    "        risk_out = F.sigmoid(self.risk_head(main))\n",
    "\n",
    "        return  risk_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "themodel = PrognosisModel()\n",
    "themodel.load_state_dict(torch.load('./imaging_prognosis_model_teacher.pt'))\n",
    "themodel.to('cuda')\n",
    "\n",
    "themodel.eval()\n",
    "\n",
    "no_shuffle_valid_dataset = data.DataLoader(UnLabeledDataset(mimic_cancer), batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "output_prediction_list = []\n",
    "for batch in no_shuffle_valid_dataset:\n",
    "    x_text_ids = batch[0].to('cuda')\n",
    "    x_attention_mask = batch[1].to('cuda')\n",
    "    with torch.no_grad():\n",
    "        predictions = themodel(x_text_ids, x_attention_mask).detach().cpu().numpy()\n",
    "    output_prediction_list.append(predictions)\n",
    "\n",
    "\n",
    "output_predictions = np.concatenate(output_prediction_list).squeeze(1)\n",
    "\n",
    "\n",
    "output_mimic = mimic_cancer.copy()\n",
    "output_mimic['risk_scores'] = output_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mimic.to_csv('./data/mimic_imaging_risk_scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class PseudoLabeledDataset(data.Dataset):\n",
    "    def __init__(self, pandas_dataset):\n",
    "        self.data = pandas_dataset.copy()\n",
    "        self.indices = self.data.index.unique()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', truncation_side='left')        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # how many notes in the dataset\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data for notes corresponding to indices passed\n",
    "        this_index = self.indices[index]\n",
    "        pand = self.data.loc[this_index, :]\n",
    "        #label = torch.tensor(pand.progression, dtype=torch.float32)\n",
    "    \n",
    "        encoded = self.tokenizer(pand['text'], padding='max_length', truncation=True)\n",
    "\n",
    "        x_text_tensor = torch.tensor(encoded.input_ids, dtype=torch.long)\n",
    "        x_attention_mask = torch.tensor(encoded.attention_mask, dtype=torch.long)\n",
    "        \n",
    "        #y_class_status = torch.tensor(pand.class_status, dtype=torch.long)\n",
    "\n",
    "        risk_score = pand['risk_scores']\n",
    "        return x_text_tensor, x_attention_mask, risk_score\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "\n",
    "class LabeledDataset(data.Dataset):\n",
    "    def __init__(self, pandas_dataset):\n",
    "        self.data = pandas_dataset.copy()\n",
    "        self.indices = self.data.index.unique()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased', truncation_side='left')        \n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        # how many notes in the dataset\n",
    "        return len(self.indices)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # get data for notes corresponding to indices passed\n",
    "        this_index = self.indices[index]\n",
    "        pand = self.data.loc[this_index, :]\n",
    "    \n",
    "        encoded = self.tokenizer(pand['text'], padding='max_length', truncation=True)\n",
    "\n",
    "        x_text_tensor = torch.tensor(encoded.input_ids, dtype=torch.long)\n",
    "        x_attention_mask = torch.tensor(encoded.attention_mask, dtype=torch.long)\n",
    "\n",
    "        y_time_to_death = torch.tensor(pand.time_to_death, dtype=torch.float32)\n",
    "        y_died = torch.tensor(pand.died, dtype=torch.float32)\n",
    "        \n",
    "     \n",
    "        return x_text_tensor, x_attention_mask, y_time_to_death, y_died\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn import functional as F\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import LSTM, Linear, Embedding, Conv1d, MaxPool1d, GRU, LSTMCell, Dropout, Module, Sequential, ReLU\n",
    "\n",
    "   \n",
    "class PrognosisModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(PrognosisModel, self).__init__()\n",
    "        \n",
    "        self.bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        self.risk_head = Sequential(Linear(768, 128), ReLU(), Linear(128,1))\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x_text_tensor, x_attention_mask):\n",
    "        # x should be tuple of input IDs, then attention mask\n",
    "        \n",
    "        main = self.bert(x_text_tensor, x_attention_mask)\n",
    "        main = main.last_hidden_state[:,0,:].squeeze(1)\n",
    "\n",
    "                                          \n",
    "        risk_out = F.sigmoid(self.risk_head(main))\n",
    "\n",
    "        return  risk_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train loop\n",
    "from transformers import get_scheduler\n",
    "from torch.optim import AdamW, Adam\n",
    "#, get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def train_model(model, num_epochs, trainloader, validloader=None, device='cuda'):\n",
    "    \n",
    "    \n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "    num_training_steps = num_epochs * len(trainloader)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    model.to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):  \n",
    "        running_train_loss = 0.0\n",
    "        mean_train_loss = 0.0\n",
    "        \n",
    "        running_valid_loss = 0.0\n",
    "        mean_valid_loss = 0.0\n",
    "\n",
    "        num_train_batches = len(trainloader)\n",
    "                \n",
    "        model.train()\n",
    "\n",
    "        for i, batch in enumerate(trainloader, 0):\n",
    "            input_ids, input_masks, risk_score = [x.to(device) for x in batch]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred_h_t = model(input_ids, input_masks).squeeze(1)            \n",
    "\n",
    "\n",
    "                \n",
    "            prognosis_loss = F.binary_cross_entropy(pred_h_t, risk_score)\n",
    "            prognosis_loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            running_train_loss += prognosis_loss.detach().cpu().numpy()\n",
    "            mean_train_loss = running_train_loss / (i+1)\n",
    "\n",
    "\n",
    "            print('Training Epoch: ' + str(epoch+1) + ', batch: ' + str(i + 1) + '/' + str(num_train_batches) + ' this_loss:' + str(prognosis_loss.detach().cpu().numpy()) \n",
    "                  +', train loss: ' + str(mean_train_loss), end='\\r', flush=True)\n",
    "        \n",
    "        print('\\n')\n",
    "        # eval on valid\n",
    "        \n",
    "        # if validloader is not None:\n",
    "        #     model.eval()\n",
    "\n",
    "            \n",
    "        #     for i, batch in enumerate(validloader, 0):\n",
    "        #         input_ids, input_masks, risk_score = [x.to(device) for x in batch]\n",
    "                    \n",
    "        #         with torch.no_grad():\n",
    "        #             pred_h_t = model(input_ids, input_masks).squeeze(1)\n",
    "\n",
    "\n",
    "                    \n",
    "        #         prognosis_loss = F.binary_cross_entropy(pred_h_t, risk_scorte)\n",
    "    \n",
    "        #         running_valid_loss += prognosis_loss.data.cpu().numpy()\n",
    "                    \n",
    "        #     mean_valid_loss = running_valid_loss / (i+1)\n",
    "\n",
    "    \n",
    "        #     print('Validation Epoch: ' + str(epoch+1) +', validation loss: ' + str(mean_valid_loss), end='\\r', flush=True)            # \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch: 1, batch: 13603/13603 this_loss:0.14987479, train loss: 0.089875888120483539\n",
      "\n",
      "Training Epoch: 2, batch: 13603/13603 this_loss:0.07460602, train loss: 0.088597042857833821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# actual student model training, commented out after model trained.\n",
    "\n",
    "#themodel = PrognosisModel().to('cuda')\n",
    "#trainloader = data.DataLoader(PseudoLabeledDataset(output_mimic.reset_index(drop=True)), batch_size=16, num_workers=8, shuffle=True)\n",
    "#validloader = data.DataLoader(LabeledDataset(validation.reset_index(drop=True)), batch_size=16, num_workers=8, shuffle=True)\n",
    "#train_model(themodel,2, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(themodel.state_dict(), 'imaging_prognosis_model_student.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out actual validation dataset\n",
    "themodel = PrognosisModel()\n",
    "themodel.load_state_dict(torch.load('imaging_prognosis_model_student.pt'))\n",
    "themodel.to('cuda')\n",
    "\n",
    "\n",
    "themodel.eval()\n",
    "\n",
    "no_shuffle_valid_dataset = data.DataLoader(LabeledDataset(test), batch_size=16, shuffle=False, num_workers=0)\n",
    "\n",
    "event_times = []\n",
    "events = []\n",
    "output_prediction_list = []\n",
    "for batch in no_shuffle_valid_dataset:\n",
    "    x_text_ids = batch[0].to('cuda')\n",
    "    x_attention_mask = batch[1].to('cuda')\n",
    "    event_times.append(batch[2].detach().cpu().numpy())\n",
    "    events.append(batch[3].detach().cpu().numpy())\n",
    "    with torch.no_grad():\n",
    "        predictions = themodel(x_text_ids, x_attention_mask).detach().cpu().numpy()\n",
    "    output_prediction_list.append(predictions)\n",
    "\n",
    "\n",
    "output_predictions = np.concatenate(output_prediction_list).squeeze(1)\n",
    "event_times = np.concatenate(event_times)\n",
    "events = np.concatenate(events)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.metrics import concordance_index_censored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7578195176372534, 1450243, 463462, 0, 181)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concordance_index_censored(np.where(events==1, True, False), event_times, output_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
